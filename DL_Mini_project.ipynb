{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nDpQ6wM7tnN-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPfybRqvttW4",
        "outputId": "a21647a4-e344-4321-fbe1-1d1c14614e52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "val_ratio = 0.2\n",
        "train_dataset, val_dataset = random_split(trainset, [int((1 - val_ratio) * len(trainset)),\n",
        "                                          int(val_ratio * len(trainset))])\n",
        "batch_size = 32\n",
        "train_dl = DataLoader(train_dataset, batch_size, shuffle=True, pin_memory=True)\n",
        "val_dl = DataLoader(val_dataset, batch_size, shuffle=True, pin_memory=True)\n",
        "test_dl = DataLoader(testset, batch_size, shuffle=True, pin_memory=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slA8ZTGlttpl",
        "outputId": "dc70cef0-9de2-4bde-eb7e-3eeef3824205"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 53116466.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "  return torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
        "    \n",
        "def to_device(entity, device):\n",
        "    if isinstance(entity, (list,tuple)):\n",
        "        return [to_device(x, device) for x in entity]\n",
        "    return entity.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "device = get_default_device()\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "test_dl = DeviceDataLoader(test_dl, device)"
      ],
      "metadata": {
        "id": "_s4jl6wZtuAO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "tSViV5F-tuKU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet9(nn.Module):\n",
        "    def __init__(self, in_channels, num_Classes):\n",
        "      super(ResNet9, self).__init__()\n",
        "      self.conv1 = conv_block(in_channels, 64)\n",
        "      self.conv2 = conv_block(64, 128, pool=True)\n",
        "      self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "\n",
        "      self.conv3 = conv_block(128, 256, pool=True)\n",
        "      self.conv4 = conv_block(256, 512, pool=True)\n",
        "      self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
        "\n",
        "      self.classifier = nn.Sequential(nn.MaxPool2d(4), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(512, num_Classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "      out = self.conv1(x)\n",
        "      out = self.conv2(out)\n",
        "      out = self.res1(out) + out\n",
        "      out = self.conv3(out)\n",
        "      out = self.conv4(out)\n",
        "      out = self.res2(out) + out\n",
        "      out = self.classifier(out)\n",
        "      return out"
      ],
      "metadata": {
        "id": "9o5Cyj5BtucC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet9(3, 10)"
      ],
      "metadata": {
        "id": "pwh4deQXt3UP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "def accuracy(logits, labels):\n",
        "    pred, predClassId = torch.max(logits, dim=1)\n",
        "    return torch.tensor(torch.sum(predClassId == labels).item() / len(logits))\n",
        "\n",
        "def evaluate(model, dl, loss_func):\n",
        "  model.eval()\n",
        "  batch_losses, batch_accs = [], []\n",
        "  for images, labels in val_dl:\n",
        "    with torch.no_grad():\n",
        "      logits = model(images)\n",
        "    batch_losses.append(loss_func(logits, labels))\n",
        "    batch_accs.append(accuracy(logits, labels))\n",
        "  epoch_avg_loss = torch.stack(batch_losses).mean()\n",
        "  epoch_avg_acc = torch.stack(batch_accs).mean()\n",
        "  return epoch_avg_loss, epoch_avg_acc\n",
        "\n",
        "def train(model, train_dl, val_dl, epochs, max_lr, loss_func, optim):\n",
        "  optimizer = optim(model.parameters(), max_lr)\n",
        "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs*len(train_dl))\n",
        "\n",
        "  results = []\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    lrs = []\n",
        "    for images, labels in train_dl:\n",
        "      logits = model(images)\n",
        "      loss = loss_func(logits, labels)\n",
        "      train_losses.append(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      lrs.append(optimizer.param_groups[0][\"lr\"])\n",
        "      scheduler.step()\n",
        "    epoch_train_loss = torch.stack(train_losses).mean()\n",
        "\n",
        "    epoch_avg_loss, epoch_avg_acc = evaluate(model, val_dl, loss_func)\n",
        "\n",
        "    results.append({'avg_valid_loss': epoch_avg_loss,\n",
        "                    'avg_valid_acc': epoch_avg_acc,\n",
        "                    'avg_train_loss': epoch_train_loss,\n",
        "                    'lr': lrs})\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "1LVBD7Art8Z-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = to_device(model, device)\n",
        "epochs = 8\n",
        "max_lr = 1e-2\n",
        "loss_func = nn.functional.cross_entropy\n",
        "optim = torch.optim.Adam\n",
        "results = train(model, train_dl, val_dl, epochs, max_lr, loss_func, optim)"
      ],
      "metadata": {
        "id": "P_TeWKzJt78u"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for result in results:\n",
        "  print(result[\"avg_valid_acc\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npYGkqIIxQ6n",
        "outputId": "074adfa2-df9b-4757-f6e6-e39438a9d662"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.8199)\n",
            "tensor(0.7507)\n",
            "tensor(0.8154)\n",
            "tensor(0.8253)\n",
            "tensor(0.8633)\n",
            "tensor(0.8791)\n",
            "tensor(0.8929)\n",
            "tensor(0.8990)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, test_acc = evaluate(model, test_dl, loss_func)"
      ],
      "metadata": {
        "id": "hGjRhOvpt_tp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrgtjKrM0RQJ",
        "outputId": "e5959415-328a-49ec-b411-32a8d610f496"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8946)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zokPl8QZ0VMZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}